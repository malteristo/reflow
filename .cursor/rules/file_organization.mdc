---
description: 
globs: 
alwaysApply: true
---
# Adaptive File Organization and Modularity

## **Adaptive Organization Philosophy**

- **Function Over Form**: Organize by what code does, not where it "should" go according to rigid structure
- **Emergent Architecture**: Let optimal organization emerge from actual code patterns and usage
- **Refactor When Needed**: Reorganize when current structure inhibits development or understanding
- **Document Decisions**: Track organizational choices and their reasoning for future reference

## **File Size Management**

- **File Size Limits:**
  - **Hard Limit**: No single file should exceed 1,000 lines
  - **Soft Limit**: Files over 500 lines should be evaluated for splitting
  - **Warning Threshold**: Files over 300 lines require architectural review

- **File Size Checkpoints:**
  ```python
  # ✅ DO: Check file size during development
  # If file approaches 300 lines, consider:
  # 1. Can classes be extracted to separate modules?
  # 2. Can utility functions be moved to utils/?
  # 3. Can related functionality be grouped into submodules?
  
  # ❌ DON'T: Continue adding to files over 500 lines without refactoring
  ```

## **Proven Modular Refactoring Patterns**

### **Pattern 1: Service Layer Modularization**
**Successfully applied to**: `api_embedding_service.py`, `config.py`, `model_change_detection.py`

```python
# ✅ PROVEN PATTERN: Service Layer with Functional Boundaries
# Before: Large service class (875-954 lines)
# After: Modular package with clear responsibilities

# Structure that works consistently:
src/module/service_name/
├── __init__.py          # Public API exports (40-70 lines)
├── exceptions.py        # Error hierarchy (60-100 lines)  
├── config.py           # Configuration management (150-200 lines)
├── client.py           # External client/HTTP logic (150-250 lines)
├── core_service.py     # Main service orchestration (300-400 lines)
└── specialized.py      # Domain-specific logic (100-200 lines)

# Proven benefits:
# - 93-96% file size reduction achieved
# - 100% backward compatibility maintained
# - Enhanced testability and maintainability
# - Clear separation of concerns
```

### **Pattern 2: Pipeline Component Extraction**
**Successfully applied to**: `document_insertion.py`, `integration_pipeline.py`

```python
# ✅ PROVEN PATTERN: Pipeline Decomposition
# Before: Monolithic pipeline (673-723 lines)
# After: Stage-based modular architecture

# Structure that delivers results:
src/module/pipeline_name/
├── __init__.py          # Pipeline API (40-60 lines)
├── models.py           # Data structures (70-160 lines)
├── validation.py       # Input validation stage (130-200 lines)
├── processing.py       # Core processing stage (200-400 lines)
├── integration.py      # External integration stage (100-200 lines)
└── managers.py         # Supporting managers (140-250 lines)

# Validated outcomes:
# - Natural processing stage boundaries
# - Improved transaction safety
# - Better error isolation
# - Enhanced testing granularity
```

### **Pattern 3: Schema/Type System Organization**
**Successfully applied to**: `metadata_schema.py`

```python
# ✅ PROVEN PATTERN: Type System Modularization
# Before: Large schema file (596 lines)
# After: Type-based component organization

# Effective structure:
src/module/schema_name/
├── __init__.py          # Complete type exports (40-70 lines)
├── enums.py            # Enumeration types (60-100 lines)
├── core_types.py       # Primary data classes (150-200 lines)
├── specialized_types.py # Domain-specific classes (170-200 lines)
├── hierarchy.py        # Complex nested structures (60-150 lines)
└── validation.py       # Validation and factories (150-250 lines)

# Proven advantages:
# - Clear type system boundaries
# - Enhanced schema evolution capability
# - Improved import clarity
# - Better validation separation
```

## **Validated Backward Compatibility Strategy**

```python
# ✅ PROVEN APPROACH: Seamless Migration Pattern
# Used successfully across 5 major refactorings

# Original module becomes compatibility layer:
# src/module/original_file.py (now 40-60 lines)
"""
Backward compatibility layer for modular package.
Imports all public API from modular structure.
"""

from .modular_package import (
    # Import everything from new structure
    AllPublicClasses,
    AllPublicFunctions,
    AllPublicConstants
)

# Module-level compatibility imports
import logging  # Original module-level imports preserved

# Complete __all__ export for API surface
__all__ = ['AllPublicClasses', 'AllPublicFunctions', ...]

# Results validated across 5 refactorings:
# - Zero import breakage
# - Zero functionality loss
# - Zero performance degradation
# - Complete API surface preservation
```

## **File Size Impact Metrics (Validated)**

```python
# ✅ MEASURED OUTCOMES from 5 Major Refactorings:

# api_embedding_service.py: 954 → 52 lines (95% reduction)
# config.py: 875 → 36 lines (96% reduction)  
# model_change_detection.py: 852 → 48 lines (94% reduction)
# document_insertion.py: 723 → 53 lines (93% reduction)
# integration_pipeline.py: 673 → 47 lines (93% reduction)

# CUMULATIVE IMPACT:
# - Total lines reduced: 4,077 → 236 lines
# - Overall reduction: 94%
# - Warning-level violations: 5 → 0 (100% resolution)
# - Modular packages created: 5
# - Total focused modules: 31 (averaging 120 lines each)

# QUALITY IMPROVEMENTS:
# - Maintainability: Significantly enhanced
# - Testability: Individual component testing
# - Readability: Clear functional boundaries
# - Extensibility: Easier to add new functionality
```

## **Modular Package __init__.py Template**

```python
# ✅ PROVEN TEMPLATE: Effective __init__.py structure
# Pattern validated across 5 successful refactorings

"""
[Package Name] for [System Component].

This package provides [core functionality description]
with modular architecture for maintainability and testability.

Public API:
- [Primary Classes]: [Class1, Class2, Class3]
- [Supporting Components]: [Component1, Component2]
- [Utilities]: [Function1, Function2]
- [Constants]: [CONSTANT1, CONSTANT2]
"""

# Import organization (proven effective):

# 1. Core/Primary components first
from .primary_module import PrimaryClass, SecondaryClass

# 2. Supporting components
from .supporting_module import SupportingClass, HelperClass

# 3. Utilities and functions
from .utilities_module import (
    utility_function,
    helper_function,
    validation_function
)

# 4. Constants and enums
from .constants_module import (
    IMPORTANT_CONSTANT,
    ConfigurationEnum
)

# Complete API surface (essential for compatibility)
__all__ = [
    # Group exports logically
    'PrimaryClass',
    'SecondaryClass', 
    'SupportingClass',
    'HelperClass',
    'utility_function',
    'helper_function',
    'validation_function',
    'IMPORTANT_CONSTANT',
    'ConfigurationEnum'
]
```

## **Adaptive Organization Principles**

- **Responsibility-Based Grouping:**
  - Group code by what it does, not by type
  - Related functionality stays together even if it spans "layers"
  - Split when responsibilities become clear and distinct

- **Natural Emergence:**
  ```python
  # ✅ DO: Let structure emerge from actual usage patterns
  # Example: If document processing naturally splits into:
  # - Parsing logic (300+ lines)
  # - Chunking logic (400+ lines)  
  # - Metadata extraction (200+ lines)
  # Then create separate modules for each

  # ❌ DON'T: Force code into predefined "service/model/util" boxes
  # if it doesn't naturally fit that way
  ```

- **Flexible Hierarchy:**
  ```
  # ✅ ADAPTIVE: Structure grows with complexity
  src/module/
  ├── __init__.py              # Public API exports
  ├── simple_component.py      # Small, focused module (< 300 lines)
  └── complex_component/       # Complex component broken down
      ├── __init__.py          # Component public API
      ├── core_logic.py        # Main logic (< 500 lines)
      ├── helpers.py           # Supporting functions
      └── specialized/         # Further breakdown if needed
          ├── parser.py
          └── formatter.py
  ```

## **Dynamic Restructuring Guidelines**

- **When to Restructure:**
  ```python
  # ✅ DO: Restructure when you encounter these signals:
  # - File exceeds 500 lines
  # - Scrolling frequently to find code
  # - Multiple distinct responsibilities in one file
  # - Import statements becoming unwieldy
  # - Test files becoming hard to navigate
  # - Circular dependency issues
  
  # ✅ DO: Restructure proactively, not reactively
  # Don't wait until file becomes unmanageable
  ```

- **How to Restructure:**
  ```python
  # PROVEN APPROACH (5 successful applications):
  
  # 1. ANALYZE: Identify natural functional boundaries
  # - Look for distinct classes with different purposes
  # - Identify groups of related utility functions
  # - Find different abstraction levels
  # - Analyze import patterns (what's used together?)
  
  # 2. DESIGN: Create modular package structure
  # - Apply proven patterns (service layer, pipeline, schema)
  # - Design __init__.py for complete API export
  # - Plan backward compatibility layer
  # - Ensure no circular dependencies
  
  # 3. EXTRACT: Implement modular structure
  # - Create package directory structure
  # - Extract modules by functional responsibility
  # - Implement __init__.py with full exports
  # - Replace original file with compatibility layer
  
  # 4. VALIDATE: Comprehensive verification
  # - Verify file size reduction achieved
  # - Confirm zero import breakage
  # - Run complete test suite
  # - Check performance preservation
  ```

## **Organizational Decision Tracking**

- **Document Architectural Decisions:**
  ```python
  # ✅ DO: Keep a record of organizational decisions
  # In module __init__.py or dedicated docs:
  
  """
  Module Organization History:
  
  2024-01: Initially single file (document_processor.py)
  2024-01: Split into parser/chunker/metadata (file grew to 5,820 lines)
  Decision: Functional responsibility separation worked better than layer separation
  
  Current structure:
  - parser.py: Markdown parsing and rule processing
  - chunker.py: Document chunking and splitting
  - metadata.py: Frontmatter and metadata extraction
  - utils.py: Shared utilities
  
  Lessons learned:
  - Utility functions are used across all modules
  - Parser and chunker have clean separation
  - Metadata extraction is truly independent
  """
  ```

- **Track Patterns That Work:**
  ```python
  # ✅ VALIDATED: Successful organizational patterns from production use
  
  # Pattern: Large Service Classes → Functional Component Modules
  # Successfully applied to: api_embedding_service, config, model_change_detection
  # Result: 94-96% size reduction, maintained functionality
  
  # Pattern: Processing Pipelines → Stage-Based Modules  
  # Successfully applied to: document_insertion, integration_pipeline
  # Result: 93% size reduction, improved transaction safety
  
  # Pattern: Schema/Type Systems → Type-Based Organization
  # Successfully applied to: metadata_schema
  # Result: 92% size reduction, enhanced schema evolution
  ```

## **TDD Integration with Adaptive Organization**

- **Test Structure Follows Code Structure:**
  ```python
  # ✅ DO: Keep test organization in sync with code organization
  # When you split src/core/document_processor.py into:
  # - src/core/document_processor/parser.py
  # - src/core/document_processor/chunker.py
  # 
  # Also split tests/unit/test_document_processor.py into:
  # - tests/unit/document_processor/test_parser.py
  # - tests/unit/document_processor/test_chunker.py
  ```

- **Enhanced REFACTOR Phase:**
  - **Code Refactoring**: Improve quality within existing structure
  - **Architectural Refactoring**: Reorganize structure when needed
  - Both phases must maintain 100% test coverage

## **Real-World Success Examples**

### **Example 1: API Service Refactoring**
```python
# ✅ ACTUAL SUCCESS: api_embedding_service.py refactoring
# BEFORE: 954 lines (highest priority warning-level file)

# AFTER: Modular package structure
src/research_agent_backend/core/api_embedding_service/
├── __init__.py (64 lines)    # Complete public API
├── exceptions.py (87 lines)  # Error hierarchy  
├── config.py (177 lines)     # Configuration with validation
├── client.py (207 lines)     # HTTP client with retry logic
├── batch_processor.py (202)  # Batch processing optimization
├── model_integration.py (161) # Model change detection
└── service.py (390 lines)    # Main service orchestration

# RESULTS ACHIEVED:
# - Original file: 954 → 52 lines (95% reduction)
# - All functionality preserved
# - Enhanced testability
# - Zero breaking changes
# - No performance degradation
```

### **Example 2: Configuration System Refactoring**
```python
# ✅ ACTUAL SUCCESS: config.py refactoring  
# BEFORE: 875 lines (critical warning-level file)

# AFTER: Responsibility-based modules
src/research_agent_backend/utils/config/
├── __init__.py (47 lines)         # Public API exports
├── paths.py (42 lines)            # Path management
├── file_operations.py (198 lines) # File I/O operations
├── schema_validation.py (167)     # Schema validation logic
├── inheritance.py (201 lines)     # Config inheritance
├── environment.py (158 lines)     # Environment handling
└── manager.py (343 lines)         # Main ConfigManager

# RESULTS ACHIEVED:
# - Original file: 875 → 36 lines (96% reduction)
# - Schema validation preserved
# - Environment override system maintained
# - Configuration inheritance working
# - Complete backward compatibility
```

### **Example 3: Pipeline Decomposition**
```python
# ✅ ACTUAL SUCCESS: document_insertion.py refactoring
# BEFORE: 723 lines (processing pipeline complexity)

# AFTER: Stage-based pipeline organization
src/research_agent_backend/core/document_insertion/
├── __init__.py (101 lines)      # Pipeline API
├── exceptions.py (62 lines)     # Error handling
├── validation.py (141 lines)    # Document validation
├── chunking.py (132 lines)      # Chunking algorithms
├── embeddings.py (74 lines)     # Embedding generation
├── transactions.py (86 lines)   # Transaction management
└── manager.py (402 lines)       # Pipeline orchestration

# RESULTS ACHIEVED:
# - Original file: 723 → 53 lines (93% reduction)
# - Transaction safety preserved
# - Pipeline stages clearly separated
# - Enhanced error isolation
# - Improved testing granularity
```

## **Migration Strategies**

- **Gradual Migration:**
  ```python
  # ✅ DO: Migrate incrementally to minimize risk
  # 1. Extract utilities first (lowest risk)
  # 2. Extract standalone classes
  # 3. Extract interdependent classes last
  # 4. Update imports gradually
  # 5. Run tests after each extraction
  ```

- **Maintaining Backward Compatibility:**
  ```python
  # ✅ PROVEN: Compatibility pattern (validated across 5 refactorings)
  # Old: from src.core.document_processor import DocumentProcessor
  # New structure with compatibility:
  
  # src/core/document_processor.py (compatibility layer)
  from .document_processor import (
      # Import everything from modular package
      DocumentProcessor,
      AllRelatedClasses,
      AllUtilityFunctions
  )
  
  # Result: Zero breaking changes, complete functionality preservation
  ```

## **Organization Quality Metrics**

- **Good Organization Indicators:**
  ```python
  # ✅ Signs of good organization (validated metrics):
  # - Average file size < 300 lines
  # - No files > 500 lines (warning threshold)
  # - Clear module responsibilities
  # - Minimal circular dependencies
  # - Easy to find relevant code
  # - Tests mirror code structure
  # - Import statements are clean and minimal
  # - 100% backward compatibility maintained
  ```

- **Organization Smells:**
  ```python
  # ❌ Signs of poor organization:
  # - Files > 500 lines
  # - Deep inheritance hierarchies
  # - Utility functions scattered everywhere
  # - Unclear module boundaries
  # - Frequent circular import issues
  # - Long import blocks
  ```

## **File Size Monitoring Integration**

- **Use Monitoring Tools:**
  ```bash
  # ✅ DO: Regular monitoring with scripts/check_file_size.py
  python scripts/check_file_size.py --root src
  
  # ✅ DO: Set up development habits
  alias check-sizes="python scripts/check_file_size.py --root src"
  alias check-large="find src -name '*.py' -exec wc -l {} \; | awk '$1 > 300' | sort -nr"
  ```

- **Warning-Level File Tracking:**
  ```bash
  # ✅ PROVEN: Monitor warning-level files (500-999 lines)
  find src -name "*.py" -type f -exec wc -l {} + | awk '{if ($1 >= 500 && $1 < 1000) print $1 " " $2}' | sort -nr
  
  # Success metric: Reduced from 5 warning-level files to 0
  # Maintained: Zero critical-level files (1000+ lines)
  ```

## **References**

- **Related Rules**: [dev_workflow.mdc](mdc:.cursor/rules/dev_workflow.mdc), [test_driven_development.mdc](mdc:.cursor/rules/test_driven_development.mdc)
- **Project Standards**: [ra-001-project-overview-and-standards.mdc](mdc:.cursor/rules/ra-001-project-overview-and-standards.mdc)
- **Success Patterns**: Based on 5 validated refactorings with 94% average file size reduction
